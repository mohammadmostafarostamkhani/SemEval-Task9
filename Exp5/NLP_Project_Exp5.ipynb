{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aoKnGMvyu6sp",
        "jh2aua1N1xT9",
        "87n_a9buJo6g",
        "943oqyS411gI",
        "FR9OR2lt7DWq",
        "bY4u7hSPxMXC",
        "60ELy8EVaQKn",
        "03lqdpuIfR-p",
        "KKw5AMGpfWNf",
        "j-hWk9fXZlho"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "ncfyuncDwoxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install emoji\n",
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "AERHrOphGHdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import plotly.express as px\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "# from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import emoji\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModel, AutoConfig\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers.modeling_outputs import TokenClassifierOutput, SequenceClassifierOutput\n",
        "from transformers import AdamW, get_scheduler\n",
        "from datasets import load_metric, Dataset\n",
        "from statistics import mean"
      ],
      "metadata": {
        "id": "_GIr10eHwmQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Drive for Reading Data"
      ],
      "metadata": {
        "id": "aoKnGMvyu6sp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJjAMPNctlfg",
        "outputId": "194a0e12-bb61-42cd-b735-b2aff90171ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd 'drive/MyDrive/NLP_Project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPjgmd2yu1ty",
        "outputId": "79789813-4d13-430d-d033-de663d7ba57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils"
      ],
      "metadata": {
        "id": "y37V0aPZZ6vQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path = \"train.csv\"):\n",
        "  df = pd.read_csv(file_path)\n",
        "  df['len'] = df['text'].apply(lambda x: len(x))\n",
        "  df['label'] = df['label'].astype('float32')\n",
        "  \n",
        "  return df\n",
        "\n",
        "def filter_tweet_language(df, language = \"English\"):\n",
        "  return df[df['language']==language]\n",
        "\n",
        "def filter_tweet_intimacy(df, lower_bound = 1, upper_bound = 5):\n",
        "  return df.loc[(df['label'] >= lower_bound) & (df['label'] <= upper_bound)]\n",
        "\n",
        "def train_val_test_split(df, train_portion = 0.9, val_portion = 0.05, test_portion = 0.05):\n",
        "    df_train, df_val, df_test, _ = np.split(df.sample(frac=1, random_state=42), [int(train_portion * len(df)), int((train_portion + val_portion) * len(df)), int((train_portion + val_portion + test_portion) * len(df))])\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "def extract_emojis(df):\n",
        "    emojis_list = list()\n",
        "    for s in df['text']:\n",
        "        emojis_in_text = emoji.distinct_emoji_list(s)\n",
        "        if len(emojis_in_text)>0:\n",
        "            emojis_list.extend(emojis_in_text)\n",
        "    return list(set(emojis_list))"
      ],
      "metadata": {
        "id": "pWUL9DmuZ8Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace Models"
      ],
      "metadata": {
        "id": "JnbTO5GX4j_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyperparameters"
      ],
      "metadata": {
        "id": "Od3SAtJX3354"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 6\n",
        "BATCH_SIZE = 32\n",
        "PATH_TO_SAVE = \"./checkpoint\""
      ],
      "metadata": {
        "id": "ct3-Qocy370h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating dataset"
      ],
      "metadata": {
        "id": "d4TvPVrH5B1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RegressionIntimacyDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.all_data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        # tokenized texts of our dataset\n",
        "        self.texts = [self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") \n",
        "                                for text in self.all_data['text']]\n",
        "\n",
        "        # intimacy scores\n",
        "        scaler = MinMaxScaler()\n",
        "        self.labels = scaler.fit_transform(self.all_data['label'].to_numpy().reshape(-1, 1))\n",
        "    \n",
        "    def classes(self,):\n",
        "        return self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "    \n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "    \n",
        "    def get_max_setntence_len(self):\n",
        "        # get length of longest sentence in our dataset\n",
        "        return max(self.all_data['len'])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_labels = self.get_batch_labels(idx)\n",
        "        \n",
        "        return batch_texts, batch_labels"
      ],
      "metadata": {
        "id": "rpbZbbNU4jMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\""
      ],
      "metadata": {
        "id": "iSaK5OTfAx67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer for tokenization of texts\n",
        "xlmt_tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
      ],
      "metadata": {
        "id": "Y0jU1hMT596h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = read_data()\n",
        "intim_dataset = RegressionIntimacyDataset(df, xlmt_tokenizer)\n",
        "print(len(intim_dataset.labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ARPx006O90",
        "outputId": "fe3c88f0-e8f5-4159-acb6-0d78ab5cdc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "643xHKa4jvvc",
        "outputId": "c70a7e6e-a80d-44cb-be65-262f412c83a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.8\n",
              "1       1.0\n",
              "2       1.0\n",
              "3       1.6\n",
              "4       1.6\n",
              "       ... \n",
              "9486    1.0\n",
              "9487    2.0\n",
              "9488    3.8\n",
              "9489    1.8\n",
              "9490    1.6\n",
              "Name: label, Length: 9491, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model definition"
      ],
      "metadata": {
        "id": "tWHRgZJc-FHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlmt_model = AutoModel.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-eU8BgzqaFb",
        "outputId": "cdc22108-7c04-45ff-8fba-09af48523445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flag = False\n",
        "\n",
        "for name, param in xlmt_model.named_parameters():\n",
        "    if 'layer.11' in name:\n",
        "        flag = True\n",
        "\n",
        "    if flag:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "    print(name, param.requires_grad)"
      ],
      "metadata": {
        "id": "QTGgO0wtRqOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23c7bbb-1c29-4b28-c4fe-c4eec9f1f9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.word_embeddings.weight False\n",
            "embeddings.position_embeddings.weight False\n",
            "embeddings.token_type_embeddings.weight False\n",
            "embeddings.LayerNorm.weight False\n",
            "embeddings.LayerNorm.bias False\n",
            "encoder.layer.0.attention.self.query.weight False\n",
            "encoder.layer.0.attention.self.query.bias False\n",
            "encoder.layer.0.attention.self.key.weight False\n",
            "encoder.layer.0.attention.self.key.bias False\n",
            "encoder.layer.0.attention.self.value.weight False\n",
            "encoder.layer.0.attention.self.value.bias False\n",
            "encoder.layer.0.attention.output.dense.weight False\n",
            "encoder.layer.0.attention.output.dense.bias False\n",
            "encoder.layer.0.attention.output.LayerNorm.weight False\n",
            "encoder.layer.0.attention.output.LayerNorm.bias False\n",
            "encoder.layer.0.intermediate.dense.weight False\n",
            "encoder.layer.0.intermediate.dense.bias False\n",
            "encoder.layer.0.output.dense.weight False\n",
            "encoder.layer.0.output.dense.bias False\n",
            "encoder.layer.0.output.LayerNorm.weight False\n",
            "encoder.layer.0.output.LayerNorm.bias False\n",
            "encoder.layer.1.attention.self.query.weight False\n",
            "encoder.layer.1.attention.self.query.bias False\n",
            "encoder.layer.1.attention.self.key.weight False\n",
            "encoder.layer.1.attention.self.key.bias False\n",
            "encoder.layer.1.attention.self.value.weight False\n",
            "encoder.layer.1.attention.self.value.bias False\n",
            "encoder.layer.1.attention.output.dense.weight False\n",
            "encoder.layer.1.attention.output.dense.bias False\n",
            "encoder.layer.1.attention.output.LayerNorm.weight False\n",
            "encoder.layer.1.attention.output.LayerNorm.bias False\n",
            "encoder.layer.1.intermediate.dense.weight False\n",
            "encoder.layer.1.intermediate.dense.bias False\n",
            "encoder.layer.1.output.dense.weight False\n",
            "encoder.layer.1.output.dense.bias False\n",
            "encoder.layer.1.output.LayerNorm.weight False\n",
            "encoder.layer.1.output.LayerNorm.bias False\n",
            "encoder.layer.2.attention.self.query.weight False\n",
            "encoder.layer.2.attention.self.query.bias False\n",
            "encoder.layer.2.attention.self.key.weight False\n",
            "encoder.layer.2.attention.self.key.bias False\n",
            "encoder.layer.2.attention.self.value.weight False\n",
            "encoder.layer.2.attention.self.value.bias False\n",
            "encoder.layer.2.attention.output.dense.weight False\n",
            "encoder.layer.2.attention.output.dense.bias False\n",
            "encoder.layer.2.attention.output.LayerNorm.weight False\n",
            "encoder.layer.2.attention.output.LayerNorm.bias False\n",
            "encoder.layer.2.intermediate.dense.weight False\n",
            "encoder.layer.2.intermediate.dense.bias False\n",
            "encoder.layer.2.output.dense.weight False\n",
            "encoder.layer.2.output.dense.bias False\n",
            "encoder.layer.2.output.LayerNorm.weight False\n",
            "encoder.layer.2.output.LayerNorm.bias False\n",
            "encoder.layer.3.attention.self.query.weight False\n",
            "encoder.layer.3.attention.self.query.bias False\n",
            "encoder.layer.3.attention.self.key.weight False\n",
            "encoder.layer.3.attention.self.key.bias False\n",
            "encoder.layer.3.attention.self.value.weight False\n",
            "encoder.layer.3.attention.self.value.bias False\n",
            "encoder.layer.3.attention.output.dense.weight False\n",
            "encoder.layer.3.attention.output.dense.bias False\n",
            "encoder.layer.3.attention.output.LayerNorm.weight False\n",
            "encoder.layer.3.attention.output.LayerNorm.bias False\n",
            "encoder.layer.3.intermediate.dense.weight False\n",
            "encoder.layer.3.intermediate.dense.bias False\n",
            "encoder.layer.3.output.dense.weight False\n",
            "encoder.layer.3.output.dense.bias False\n",
            "encoder.layer.3.output.LayerNorm.weight False\n",
            "encoder.layer.3.output.LayerNorm.bias False\n",
            "encoder.layer.4.attention.self.query.weight False\n",
            "encoder.layer.4.attention.self.query.bias False\n",
            "encoder.layer.4.attention.self.key.weight False\n",
            "encoder.layer.4.attention.self.key.bias False\n",
            "encoder.layer.4.attention.self.value.weight False\n",
            "encoder.layer.4.attention.self.value.bias False\n",
            "encoder.layer.4.attention.output.dense.weight False\n",
            "encoder.layer.4.attention.output.dense.bias False\n",
            "encoder.layer.4.attention.output.LayerNorm.weight False\n",
            "encoder.layer.4.attention.output.LayerNorm.bias False\n",
            "encoder.layer.4.intermediate.dense.weight False\n",
            "encoder.layer.4.intermediate.dense.bias False\n",
            "encoder.layer.4.output.dense.weight False\n",
            "encoder.layer.4.output.dense.bias False\n",
            "encoder.layer.4.output.LayerNorm.weight False\n",
            "encoder.layer.4.output.LayerNorm.bias False\n",
            "encoder.layer.5.attention.self.query.weight False\n",
            "encoder.layer.5.attention.self.query.bias False\n",
            "encoder.layer.5.attention.self.key.weight False\n",
            "encoder.layer.5.attention.self.key.bias False\n",
            "encoder.layer.5.attention.self.value.weight False\n",
            "encoder.layer.5.attention.self.value.bias False\n",
            "encoder.layer.5.attention.output.dense.weight False\n",
            "encoder.layer.5.attention.output.dense.bias False\n",
            "encoder.layer.5.attention.output.LayerNorm.weight False\n",
            "encoder.layer.5.attention.output.LayerNorm.bias False\n",
            "encoder.layer.5.intermediate.dense.weight False\n",
            "encoder.layer.5.intermediate.dense.bias False\n",
            "encoder.layer.5.output.dense.weight False\n",
            "encoder.layer.5.output.dense.bias False\n",
            "encoder.layer.5.output.LayerNorm.weight False\n",
            "encoder.layer.5.output.LayerNorm.bias False\n",
            "encoder.layer.6.attention.self.query.weight False\n",
            "encoder.layer.6.attention.self.query.bias False\n",
            "encoder.layer.6.attention.self.key.weight False\n",
            "encoder.layer.6.attention.self.key.bias False\n",
            "encoder.layer.6.attention.self.value.weight False\n",
            "encoder.layer.6.attention.self.value.bias False\n",
            "encoder.layer.6.attention.output.dense.weight False\n",
            "encoder.layer.6.attention.output.dense.bias False\n",
            "encoder.layer.6.attention.output.LayerNorm.weight False\n",
            "encoder.layer.6.attention.output.LayerNorm.bias False\n",
            "encoder.layer.6.intermediate.dense.weight False\n",
            "encoder.layer.6.intermediate.dense.bias False\n",
            "encoder.layer.6.output.dense.weight False\n",
            "encoder.layer.6.output.dense.bias False\n",
            "encoder.layer.6.output.LayerNorm.weight False\n",
            "encoder.layer.6.output.LayerNorm.bias False\n",
            "encoder.layer.7.attention.self.query.weight False\n",
            "encoder.layer.7.attention.self.query.bias False\n",
            "encoder.layer.7.attention.self.key.weight False\n",
            "encoder.layer.7.attention.self.key.bias False\n",
            "encoder.layer.7.attention.self.value.weight False\n",
            "encoder.layer.7.attention.self.value.bias False\n",
            "encoder.layer.7.attention.output.dense.weight False\n",
            "encoder.layer.7.attention.output.dense.bias False\n",
            "encoder.layer.7.attention.output.LayerNorm.weight False\n",
            "encoder.layer.7.attention.output.LayerNorm.bias False\n",
            "encoder.layer.7.intermediate.dense.weight False\n",
            "encoder.layer.7.intermediate.dense.bias False\n",
            "encoder.layer.7.output.dense.weight False\n",
            "encoder.layer.7.output.dense.bias False\n",
            "encoder.layer.7.output.LayerNorm.weight False\n",
            "encoder.layer.7.output.LayerNorm.bias False\n",
            "encoder.layer.8.attention.self.query.weight False\n",
            "encoder.layer.8.attention.self.query.bias False\n",
            "encoder.layer.8.attention.self.key.weight False\n",
            "encoder.layer.8.attention.self.key.bias False\n",
            "encoder.layer.8.attention.self.value.weight False\n",
            "encoder.layer.8.attention.self.value.bias False\n",
            "encoder.layer.8.attention.output.dense.weight False\n",
            "encoder.layer.8.attention.output.dense.bias False\n",
            "encoder.layer.8.attention.output.LayerNorm.weight False\n",
            "encoder.layer.8.attention.output.LayerNorm.bias False\n",
            "encoder.layer.8.intermediate.dense.weight False\n",
            "encoder.layer.8.intermediate.dense.bias False\n",
            "encoder.layer.8.output.dense.weight False\n",
            "encoder.layer.8.output.dense.bias False\n",
            "encoder.layer.8.output.LayerNorm.weight False\n",
            "encoder.layer.8.output.LayerNorm.bias False\n",
            "encoder.layer.9.attention.self.query.weight False\n",
            "encoder.layer.9.attention.self.query.bias False\n",
            "encoder.layer.9.attention.self.key.weight False\n",
            "encoder.layer.9.attention.self.key.bias False\n",
            "encoder.layer.9.attention.self.value.weight False\n",
            "encoder.layer.9.attention.self.value.bias False\n",
            "encoder.layer.9.attention.output.dense.weight False\n",
            "encoder.layer.9.attention.output.dense.bias False\n",
            "encoder.layer.9.attention.output.LayerNorm.weight False\n",
            "encoder.layer.9.attention.output.LayerNorm.bias False\n",
            "encoder.layer.9.intermediate.dense.weight False\n",
            "encoder.layer.9.intermediate.dense.bias False\n",
            "encoder.layer.9.output.dense.weight False\n",
            "encoder.layer.9.output.dense.bias False\n",
            "encoder.layer.9.output.LayerNorm.weight False\n",
            "encoder.layer.9.output.LayerNorm.bias False\n",
            "encoder.layer.10.attention.self.query.weight False\n",
            "encoder.layer.10.attention.self.query.bias False\n",
            "encoder.layer.10.attention.self.key.weight False\n",
            "encoder.layer.10.attention.self.key.bias False\n",
            "encoder.layer.10.attention.self.value.weight False\n",
            "encoder.layer.10.attention.self.value.bias False\n",
            "encoder.layer.10.attention.output.dense.weight False\n",
            "encoder.layer.10.attention.output.dense.bias False\n",
            "encoder.layer.10.attention.output.LayerNorm.weight False\n",
            "encoder.layer.10.attention.output.LayerNorm.bias False\n",
            "encoder.layer.10.intermediate.dense.weight False\n",
            "encoder.layer.10.intermediate.dense.bias False\n",
            "encoder.layer.10.output.dense.weight False\n",
            "encoder.layer.10.output.dense.bias False\n",
            "encoder.layer.10.output.LayerNorm.weight False\n",
            "encoder.layer.10.output.LayerNorm.bias False\n",
            "encoder.layer.11.attention.self.query.weight True\n",
            "encoder.layer.11.attention.self.query.bias True\n",
            "encoder.layer.11.attention.self.key.weight True\n",
            "encoder.layer.11.attention.self.key.bias True\n",
            "encoder.layer.11.attention.self.value.weight True\n",
            "encoder.layer.11.attention.self.value.bias True\n",
            "encoder.layer.11.attention.output.dense.weight True\n",
            "encoder.layer.11.attention.output.dense.bias True\n",
            "encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "encoder.layer.11.intermediate.dense.weight True\n",
            "encoder.layer.11.intermediate.dense.bias True\n",
            "encoder.layer.11.output.dense.weight True\n",
            "encoder.layer.11.output.dense.bias True\n",
            "encoder.layer.11.output.LayerNorm.weight True\n",
            "encoder.layer.11.output.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class XLMTRegressor(nn.Module):\n",
        "    def __init__(self, model, hidden_count = 20, dropout = 0.2):\n",
        "        super(XLMTRegressor, self).__init__()\n",
        "\n",
        "        self.xlmt = model\n",
        "        self.linear = nn.Linear(768, hidden_count)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.regression = nn.Linear(hidden_count, 1)\n",
        "\n",
        "    def forward(self, input_ids = None, attention_mask = None, labels = None):\n",
        "        encoding_output = self.xlmt(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        # https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling\n",
        "        linear_output = self.linear(encoding_output[1])\n",
        "        relu_output = self.relu(linear_output)\n",
        "        dropout_output = self.dropout(relu_output)\n",
        "        final_output = self.regression(dropout_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.MSELoss()\n",
        "            loss = loss_fct(final_output, labels)\n",
        "        \n",
        "        return SequenceClassifierOutput(loss = loss, logits = final_output, hidden_states = encoding_output.hidden_states, attentions = encoding_output.attentions)"
      ],
      "metadata": {
        "id": "HUuLjyiGw0GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train model"
      ],
      "metadata": {
        "id": "jh2aua1N1xT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = RegressionIntimacyDataset(train_data, xlmt_tokenizer), RegressionIntimacyDataset(val_data, xlmt_tokenizer)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr = learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            outputs = model(input_id, mask, train_label)\n",
        "\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        eval_losses = []\n",
        "        for val_input, val_label in tqdm(val_dataloader):\n",
        "            val_label = val_label.to(device)\n",
        "            mask = val_input['attention_mask'].to(device)\n",
        "            input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_id, mask, val_label)\n",
        "            \n",
        "            model_pred = outputs.logits\n",
        "            eval_losses.append(outputs.loss.item())\n",
        "\n",
        "        print(f'loss = {mean(eval_losses)}')\n",
        "\n",
        "    torch.save(model.state_dict(), f'{PATH_TO_SAVE}')\n",
        "    \n",
        "                \n",
        "EPOCHS = 6\n",
        "model = XLMTRegressor(xlmt_model)\n",
        "LR = 1e-4\n",
        "\n",
        "df_train, df_val, df_test = train_val_test_split(df)\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39H3sDG-6ZKD",
        "outputId": "9a7eed09-3197-4da7-e2a5-fce6abde37bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 446/446 [09:27<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.026878770515322684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446/446 [09:26<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.02551545564085245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446/446 [09:26<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.02557449258863926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446/446 [09:26<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.024973321184515954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446/446 [09:26<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.02470194175839424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 446/446 [09:25<00:00,  1.27s/it]\n",
            "100%|██████████| 25/25 [00:24<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.02546728141605854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluate"
      ],
      "metadata": {
        "id": "87n_a9buJo6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_data):\n",
        "    test = RegressionIntimacyDataset(test_data, xlmt_tokenizer)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_losses = []\n",
        "        for test_input, test_label in tqdm(test_dataloader):\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            outputs = model(input_id, mask, test_label)\n",
        "\n",
        "            model_pred = outputs.logits\n",
        "            test_losses.append(outputs.loss.item())\n",
        "    \n",
        "    print(f'loss = {mean(test_losses)}')\n",
        "    \n",
        "evaluate(model, df_test)"
      ],
      "metadata": {
        "id": "XJ5UPsBP6b8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff15a6b-23d8-4974-dbce-65db968d90f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:26<00:00, 15.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.023107617252419298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation on test data codalab"
      ],
      "metadata": {
        "id": "C_UBPU0ww_00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_FOR_READ = './checkpoint'"
      ],
      "metadata": {
        "id": "3UrSquvKpnc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_test_data(file_path = \"semeval_test.csv\"):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ],
      "metadata": {
        "id": "nE7FojiKwMkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestRegressionIntimacyDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.all_data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        # tokenized texts of our dataset\n",
        "        self.texts = [self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") \n",
        "                                for text in self.all_data['text']]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.all_data)\n",
        "    \n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        \n",
        "        return batch_texts\n"
      ],
      "metadata": {
        "id": "pbp-HN7kzjFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
        "xlmt_tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
      ],
      "metadata": {
        "id": "nfNwBfBr1C7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xlmt_model = AutoModel.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\")"
      ],
      "metadata": {
        "id": "n1WZHcNkotRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdbc6e1-7818-4853-a34c-7a99023a554f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLMTRegressor(xlmt_model)\n",
        "model.load_state_dict(torch.load(f'{PATH_FOR_READ}'))\n",
        "# model.load_state_dict(torch.load(f'{PATH_FOR_READ}_{EPOCHS-1}'))\n",
        "# model.load_state_dict(torch.load(f'{PATH_FOR_READ}_{EPOCHS-1}', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "-YllGTwGoGk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2e20a4-677a-4cad-d69b-53e492eb8d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_data):\n",
        "    test = TestRegressionIntimacyDataset(test_data, xlmt_tokenizer)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=32)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    model_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_input in tqdm(test_dataloader):\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "            outputs = model(input_id, mask)\n",
        "            model_pred = outputs.logits\n",
        "            model_predictions.append(model_pred)\n",
        "    return model_predictions\n"
      ],
      "metadata": {
        "id": "yi-AqF3-w_JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_coda = read_test_data(\"train.csv\")    \n",
        "df_coda = read_test_data(\"semeval_test.csv\")    \n",
        "outputs = predict(model, df_coda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjVWchwPxZ8t",
        "outputId": "ba456afd-82f3-4e23-dd0d-5ce2cdbfaefb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 429/429 [06:54<00:00,  1.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions = [item.cpu().numpy()[0] for sublist in outputs for item in sublist]"
      ],
      "metadata": {
        "id": "wKe1ZveT3UeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_flat = min(flat_predictions)\n",
        "max_flat = max(flat_predictions)"
      ],
      "metadata": {
        "id": "TbRgo-xr765B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(flat_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2T39ho43mZZ",
        "outputId": "6dc53b8a-6f8e-4e07-deb8-bdd8986b07b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_coda['predictions'] = flat_predictions\n",
        "df_coda['predictions'] = df_coda['predictions'].apply(lambda x: (x - min_flat) * 4 / (max_flat - min_flat) + 1)\n",
        "df_coda.to_csv('results.csv')"
      ],
      "metadata": {
        "id": "EGfd-NmS3ukC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Pearson metric for train data (layer 1-10 freezed)"
      ],
      "metadata": {
        "id": "ahspfQ2IAAkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "Bc327IKvAht3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import PearsonCorrCoef\n",
        "import pandas as pd\n",
        "\n",
        "path = \"./results-train-finetune-layer11.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C67vqEcN__HU",
        "outputId": "d52105b1-1f61-45c1-9182-8e9cda92c131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  \\\n",
              "0           0             0   \n",
              "1           1             1   \n",
              "2           2             2   \n",
              "3           3             3   \n",
              "4           4             4   \n",
              "\n",
              "                                                text  label language  \\\n",
              "0  wearing a fake engagement ring so guys won’t a...    1.8  English   \n",
              "1                               Bees vs. Wasps. http    1.0  English   \n",
              "2               Here is a nice equation: 0+0-0-0+0=0    1.0  English   \n",
              "3               @user @user Enjoy each new day!😊🇨🇦🐞🐭    1.6  English   \n",
              "4  I can be having a perfectly good day then I th...    1.6  English   \n",
              "\n",
              "   predictions  \n",
              "0     1.930728  \n",
              "1     1.389495  \n",
              "2     1.299155  \n",
              "3     1.712437  \n",
              "4     1.669154  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e9fc173-3a0a-47b2-95ca-02357533961f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>language</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>wearing a fake engagement ring so guys won’t a...</td>\n",
              "      <td>1.8</td>\n",
              "      <td>English</td>\n",
              "      <td>1.930728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bees vs. Wasps. http</td>\n",
              "      <td>1.0</td>\n",
              "      <td>English</td>\n",
              "      <td>1.389495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Here is a nice equation: 0+0-0-0+0=0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>English</td>\n",
              "      <td>1.299155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>@user @user Enjoy each new day!😊🇨🇦🐞🐭</td>\n",
              "      <td>1.6</td>\n",
              "      <td>English</td>\n",
              "      <td>1.712437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>I can be having a perfectly good day then I th...</td>\n",
              "      <td>1.6</td>\n",
              "      <td>English</td>\n",
              "      <td>1.669154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e9fc173-3a0a-47b2-95ca-02357533961f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e9fc173-3a0a-47b2-95ca-02357533961f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e9fc173-3a0a-47b2-95ca-02357533961f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "target = torch.tensor(df['label'])\n",
        "preds = torch.tensor(df['predictions'])\n",
        "pearson = PearsonCorrCoef()\n",
        "pearson(preds, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33RbjiU5AzRI",
        "outputId": "987c892f-324c-4813-a872-d689498e988f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7975)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}