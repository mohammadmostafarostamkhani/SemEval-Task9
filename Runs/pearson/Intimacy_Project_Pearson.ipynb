{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncfyuncDwoxv"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AERHrOphGHdH",
        "outputId": "596f3070-eb64-486b-bde7-0a43430cb223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=ab562083fbaa6d9af847a28855480d0b3355c1ef2e8fd76dc8899c9b9ac0ab82\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.10.0-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.10.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.5.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install emoji\n",
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GIr10eHwmQ4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import plotly.express as px\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "# from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import emoji\n",
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModel, AutoConfig\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers.modeling_outputs import TokenClassifierOutput, SequenceClassifierOutput\n",
        "from transformers import AdamW, get_scheduler\n",
        "from datasets import load_metric, Dataset\n",
        "from statistics import mean\n",
        "from torchmetrics import PearsonCorrCoef, SpearmanCorrCoef\n",
        "from torchmetrics.functional import pearson_corrcoef, spearman_corrcoef\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GLOBAL_SEED = 10\n",
        "\n",
        "np.random.seed(GLOBAL_SEED)\n",
        "random.seed(GLOBAL_SEED)\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "torch.use_deterministic_algorithms(True)\n",
        "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoKnGMvyu6sp"
      },
      "source": [
        "# Mounting Drive for Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJjAMPNctlfg",
        "outputId": "5af52f30-fb0c-49b4-f0fd-2548a0e9195a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPjgmd2yu1ty",
        "outputId": "f0e84614-fb57-45aa-d237-472ce609b806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP_Project\n"
          ]
        }
      ],
      "source": [
        "cd 'drive/MyDrive/NLP_Project'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y37V0aPZZ6vQ"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWUL9DmuZ8Oa"
      },
      "outputs": [],
      "source": [
        "def read_data(file_path = \"train.csv\"):\n",
        "  df = pd.read_csv(file_path)\n",
        "  df['len'] = df['text'].apply(lambda x: len(x))\n",
        "  df['label'] = df['label'].astype('float32')\n",
        "  return df\n",
        "\n",
        "def filter_tweet_language(df, language = \"English\"):\n",
        "  return df[df['language']==language]\n",
        "\n",
        "def filter_tweet_intimacy(df, lower_bound = 1, upper_bound = 5):\n",
        "  return df.loc[(df['label'] >= lower_bound) & (df['label'] <= upper_bound)]\n",
        "\n",
        "def train_val_test_split(df, train_portion = 0.9, val_portion = 0.05, test_portion = 0.05):\n",
        "    df_train, df_val, df_test, _ = np.split(df.sample(frac=1, random_state=42), [int(train_portion * len(df)), int((train_portion + val_portion) * len(df)), int((train_portion + val_portion + test_portion) * len(df))])\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "def extract_emojis(df):\n",
        "    emojis_list = list()\n",
        "    for s in df['text']:\n",
        "        emojis_in_text = emoji.distinct_emoji_list(s)\n",
        "        if len(emojis_in_text)>0:\n",
        "            emojis_list.extend(emojis_in_text)\n",
        "    return list(set(emojis_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnbTO5GX4j_p"
      },
      "source": [
        "# HuggingFace Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od3SAtJX3354"
      },
      "source": [
        "## Hyperparameters and Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct3-Qocy370h"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-4\n",
        "PATH_TO_SAVE = \"./checkpoint\"\n",
        "PATH_FOR_READ = './checkpoint'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4TvPVrH5B1L"
      },
      "source": [
        "## creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpbZbbNU4jMP"
      },
      "outputs": [],
      "source": [
        "class RegressionIntimacyDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.all_data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        # tokenized texts of our dataset\n",
        "        self.encodings = {}\n",
        "        self.encodings['input_ids'] = np.array([np.array(self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")['input_ids'])\n",
        "                                for text in self.all_data['text']])\n",
        "        \n",
        "        self.encodings['attention_mask'] = np.array([np.array(self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")['attention_mask'])\n",
        "                                for text in self.all_data['text']])\n",
        "        \n",
        "        # intimacy scores\n",
        "        # scaler = MinMaxScaler()\n",
        "        # self.labels = scaler.fit_transform(self.all_data['label'].to_numpy().reshape(-1, 1))\n",
        "        # self.labels = self.all_data['label']\n",
        "        self.labels = self.all_data['label'].to_numpy().reshape(-1, 1)\n",
        "        # self.labels = self.all_data['label'].to_numpy().reshape(-1, 1) * 10\n",
        "    \n",
        "    def classes(self,):\n",
        "        return self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def get_max_setntence_len(self):\n",
        "        # get length of longest sentence in our dataset\n",
        "        return max(self.all_data['len'])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "2c2a2742c5f94b75b8a77d1fbdca6dfe",
            "9702942a30f34ac694d481c3eced7eac",
            "f32e18b6e30f4a728b07f8c68e463cf1",
            "99922cceccef4612bea30bd3d1080ae3",
            "f818bf2fc7ac439390684fea3fe1f8bd",
            "4022d31cab9a4586bf4d9e64e298cff7",
            "81251e1aaded4a2eb7b2caa6a55a376e",
            "c6ad614603ed4d87b6953b9fb65071c5",
            "11b367b6a93f471f97f2b5957a5c2aed",
            "564502658a134864a7c47e2cc168f24a",
            "292ea552cfe7454aaeaebb5864140231",
            "157f0cd2c7c44ccbb3c0d4d608d70a2c",
            "52c41d3b2a734c26a89f6a5176635ff0",
            "abbeec30301c4df8a12f41e8369515b0",
            "58bc82e67c064ee19bd7e784628a281c",
            "ef68bdc26ae84cfc986bf68f5d20525e",
            "7b1db388afcf4501ae85699ff8ce45b1",
            "a7834e3f18f145d5a2e9d1f99b9e7657",
            "17b69830c2d741f0b1692dbf7efefbad",
            "1bbdb34647bd4d32a1735e8cef3fb098",
            "0db57a43ada346d2a99fd08b873a8496",
            "4ab3a8192a4f4eae87cc5360263bfa98",
            "e630bda7e0194373af5241d6b142df12",
            "c43f625ab61f4545ab7d4aa1a811f9a5",
            "63959ef9d01d49869b61cc6ef247634a",
            "c6580453586842b6875fd83a52b64abd",
            "0c705f2e20b54fcd857fefcb32652c8d",
            "9c1e166e0c7340ffbef941155756c634",
            "29165982dd714021b4410a1a61de3498",
            "f1514a8f5b4a48bfac81aedfdbf7d4f4",
            "6966da6ad71e434697cdea564d84e13d",
            "b46e3dc2798040b98e22d4ea8b109ab2",
            "eb7fc6cb679041539e24fa918dd7a2ab"
          ]
        },
        "id": "iSaK5OTfAx67",
        "outputId": "073ec3f3-d25b-4701-cd2a-9e0f77fad36a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c2a2742c5f94b75b8a77d1fbdca6dfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "157f0cd2c7c44ccbb3c0d4d608d70a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ncepiece.bpe.model\";:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e630bda7e0194373af5241d6b142df12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
        "# tokenizer for tokenization of texts\n",
        "# bert_base_uncased_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # cased or uncased?\n",
        "xlmt_tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ARPx006O90",
        "outputId": "2ae16355-8fc3-45e9-80fe-487b7a7849a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23721\n",
            "0        1.8\n",
            "1        1.0\n",
            "2        1.0\n",
            "3        1.6\n",
            "4        1.6\n",
            "        ... \n",
            "23716    1.0\n",
            "23717    2.0\n",
            "23718    3.8\n",
            "23719    1.8\n",
            "23720    1.6\n",
            "Name: label, Length: 23721, dtype: float32\n"
          ]
        }
      ],
      "source": [
        "df = read_data(\"augmented_dataset.csv\")\n",
        "intim_dataset = RegressionIntimacyDataset(df, xlmt_tokenizer)\n",
        "print(len(intim_dataset.labels))\n",
        "\n",
        "print(df['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWHRgZJc-FHu"
      },
      "source": [
        "## model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "18eece111e804e3a8b7c1dafadf6ae9a",
            "051da38cb7814368bf653f970a5767ac",
            "9256856ee0c74f2281792d669096bb14",
            "eb21d8c4ebd3409c9d560799fb7b2b88",
            "760c65aeec4543848d01799e1c01578d",
            "5deefc48e0b645c6ad3a9fd108317bf2",
            "8f0a52f15d944f59bd5e27576cf9c711",
            "fed66ba067e9493ead2943783c39c2b4",
            "b1e1391b523f42d9b71103cee6cacc25",
            "61f03d9ef06d4f1e952241bade0bb6e2",
            "4d90a60a0b474194817babc5ba8c1e60"
          ]
        },
        "id": "s-eU8BgzqaFb",
        "outputId": "03950b5c-1fba-491a-c056-ddbb3a3f41c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18eece111e804e3a8b7c1dafadf6ae9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "xlmt_model = AutoModel.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTGgO0wtRqOi",
        "outputId": "753352b7-2e91-47be-8810-df52d1f1ad25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings.word_embeddings.weight False\n",
            "embeddings.position_embeddings.weight False\n",
            "embeddings.token_type_embeddings.weight False\n",
            "embeddings.LayerNorm.weight False\n",
            "embeddings.LayerNorm.bias False\n",
            "encoder.layer.0.attention.self.query.weight False\n",
            "encoder.layer.0.attention.self.query.bias False\n",
            "encoder.layer.0.attention.self.key.weight False\n",
            "encoder.layer.0.attention.self.key.bias False\n",
            "encoder.layer.0.attention.self.value.weight False\n",
            "encoder.layer.0.attention.self.value.bias False\n",
            "encoder.layer.0.attention.output.dense.weight False\n",
            "encoder.layer.0.attention.output.dense.bias False\n",
            "encoder.layer.0.attention.output.LayerNorm.weight False\n",
            "encoder.layer.0.attention.output.LayerNorm.bias False\n",
            "encoder.layer.0.intermediate.dense.weight False\n",
            "encoder.layer.0.intermediate.dense.bias False\n",
            "encoder.layer.0.output.dense.weight False\n",
            "encoder.layer.0.output.dense.bias False\n",
            "encoder.layer.0.output.LayerNorm.weight False\n",
            "encoder.layer.0.output.LayerNorm.bias False\n",
            "encoder.layer.1.attention.self.query.weight False\n",
            "encoder.layer.1.attention.self.query.bias False\n",
            "encoder.layer.1.attention.self.key.weight False\n",
            "encoder.layer.1.attention.self.key.bias False\n",
            "encoder.layer.1.attention.self.value.weight False\n",
            "encoder.layer.1.attention.self.value.bias False\n",
            "encoder.layer.1.attention.output.dense.weight False\n",
            "encoder.layer.1.attention.output.dense.bias False\n",
            "encoder.layer.1.attention.output.LayerNorm.weight False\n",
            "encoder.layer.1.attention.output.LayerNorm.bias False\n",
            "encoder.layer.1.intermediate.dense.weight False\n",
            "encoder.layer.1.intermediate.dense.bias False\n",
            "encoder.layer.1.output.dense.weight False\n",
            "encoder.layer.1.output.dense.bias False\n",
            "encoder.layer.1.output.LayerNorm.weight False\n",
            "encoder.layer.1.output.LayerNorm.bias False\n",
            "encoder.layer.2.attention.self.query.weight False\n",
            "encoder.layer.2.attention.self.query.bias False\n",
            "encoder.layer.2.attention.self.key.weight False\n",
            "encoder.layer.2.attention.self.key.bias False\n",
            "encoder.layer.2.attention.self.value.weight False\n",
            "encoder.layer.2.attention.self.value.bias False\n",
            "encoder.layer.2.attention.output.dense.weight False\n",
            "encoder.layer.2.attention.output.dense.bias False\n",
            "encoder.layer.2.attention.output.LayerNorm.weight False\n",
            "encoder.layer.2.attention.output.LayerNorm.bias False\n",
            "encoder.layer.2.intermediate.dense.weight False\n",
            "encoder.layer.2.intermediate.dense.bias False\n",
            "encoder.layer.2.output.dense.weight False\n",
            "encoder.layer.2.output.dense.bias False\n",
            "encoder.layer.2.output.LayerNorm.weight False\n",
            "encoder.layer.2.output.LayerNorm.bias False\n",
            "encoder.layer.3.attention.self.query.weight False\n",
            "encoder.layer.3.attention.self.query.bias False\n",
            "encoder.layer.3.attention.self.key.weight False\n",
            "encoder.layer.3.attention.self.key.bias False\n",
            "encoder.layer.3.attention.self.value.weight False\n",
            "encoder.layer.3.attention.self.value.bias False\n",
            "encoder.layer.3.attention.output.dense.weight False\n",
            "encoder.layer.3.attention.output.dense.bias False\n",
            "encoder.layer.3.attention.output.LayerNorm.weight False\n",
            "encoder.layer.3.attention.output.LayerNorm.bias False\n",
            "encoder.layer.3.intermediate.dense.weight False\n",
            "encoder.layer.3.intermediate.dense.bias False\n",
            "encoder.layer.3.output.dense.weight False\n",
            "encoder.layer.3.output.dense.bias False\n",
            "encoder.layer.3.output.LayerNorm.weight False\n",
            "encoder.layer.3.output.LayerNorm.bias False\n",
            "encoder.layer.4.attention.self.query.weight False\n",
            "encoder.layer.4.attention.self.query.bias False\n",
            "encoder.layer.4.attention.self.key.weight False\n",
            "encoder.layer.4.attention.self.key.bias False\n",
            "encoder.layer.4.attention.self.value.weight False\n",
            "encoder.layer.4.attention.self.value.bias False\n",
            "encoder.layer.4.attention.output.dense.weight False\n",
            "encoder.layer.4.attention.output.dense.bias False\n",
            "encoder.layer.4.attention.output.LayerNorm.weight False\n",
            "encoder.layer.4.attention.output.LayerNorm.bias False\n",
            "encoder.layer.4.intermediate.dense.weight False\n",
            "encoder.layer.4.intermediate.dense.bias False\n",
            "encoder.layer.4.output.dense.weight False\n",
            "encoder.layer.4.output.dense.bias False\n",
            "encoder.layer.4.output.LayerNorm.weight False\n",
            "encoder.layer.4.output.LayerNorm.bias False\n",
            "encoder.layer.5.attention.self.query.weight False\n",
            "encoder.layer.5.attention.self.query.bias False\n",
            "encoder.layer.5.attention.self.key.weight False\n",
            "encoder.layer.5.attention.self.key.bias False\n",
            "encoder.layer.5.attention.self.value.weight False\n",
            "encoder.layer.5.attention.self.value.bias False\n",
            "encoder.layer.5.attention.output.dense.weight False\n",
            "encoder.layer.5.attention.output.dense.bias False\n",
            "encoder.layer.5.attention.output.LayerNorm.weight False\n",
            "encoder.layer.5.attention.output.LayerNorm.bias False\n",
            "encoder.layer.5.intermediate.dense.weight False\n",
            "encoder.layer.5.intermediate.dense.bias False\n",
            "encoder.layer.5.output.dense.weight False\n",
            "encoder.layer.5.output.dense.bias False\n",
            "encoder.layer.5.output.LayerNorm.weight False\n",
            "encoder.layer.5.output.LayerNorm.bias False\n",
            "encoder.layer.6.attention.self.query.weight False\n",
            "encoder.layer.6.attention.self.query.bias False\n",
            "encoder.layer.6.attention.self.key.weight False\n",
            "encoder.layer.6.attention.self.key.bias False\n",
            "encoder.layer.6.attention.self.value.weight False\n",
            "encoder.layer.6.attention.self.value.bias False\n",
            "encoder.layer.6.attention.output.dense.weight False\n",
            "encoder.layer.6.attention.output.dense.bias False\n",
            "encoder.layer.6.attention.output.LayerNorm.weight False\n",
            "encoder.layer.6.attention.output.LayerNorm.bias False\n",
            "encoder.layer.6.intermediate.dense.weight False\n",
            "encoder.layer.6.intermediate.dense.bias False\n",
            "encoder.layer.6.output.dense.weight False\n",
            "encoder.layer.6.output.dense.bias False\n",
            "encoder.layer.6.output.LayerNorm.weight False\n",
            "encoder.layer.6.output.LayerNorm.bias False\n",
            "encoder.layer.7.attention.self.query.weight False\n",
            "encoder.layer.7.attention.self.query.bias False\n",
            "encoder.layer.7.attention.self.key.weight False\n",
            "encoder.layer.7.attention.self.key.bias False\n",
            "encoder.layer.7.attention.self.value.weight False\n",
            "encoder.layer.7.attention.self.value.bias False\n",
            "encoder.layer.7.attention.output.dense.weight False\n",
            "encoder.layer.7.attention.output.dense.bias False\n",
            "encoder.layer.7.attention.output.LayerNorm.weight False\n",
            "encoder.layer.7.attention.output.LayerNorm.bias False\n",
            "encoder.layer.7.intermediate.dense.weight False\n",
            "encoder.layer.7.intermediate.dense.bias False\n",
            "encoder.layer.7.output.dense.weight False\n",
            "encoder.layer.7.output.dense.bias False\n",
            "encoder.layer.7.output.LayerNorm.weight False\n",
            "encoder.layer.7.output.LayerNorm.bias False\n",
            "encoder.layer.8.attention.self.query.weight False\n",
            "encoder.layer.8.attention.self.query.bias False\n",
            "encoder.layer.8.attention.self.key.weight False\n",
            "encoder.layer.8.attention.self.key.bias False\n",
            "encoder.layer.8.attention.self.value.weight False\n",
            "encoder.layer.8.attention.self.value.bias False\n",
            "encoder.layer.8.attention.output.dense.weight False\n",
            "encoder.layer.8.attention.output.dense.bias False\n",
            "encoder.layer.8.attention.output.LayerNorm.weight False\n",
            "encoder.layer.8.attention.output.LayerNorm.bias False\n",
            "encoder.layer.8.intermediate.dense.weight False\n",
            "encoder.layer.8.intermediate.dense.bias False\n",
            "encoder.layer.8.output.dense.weight False\n",
            "encoder.layer.8.output.dense.bias False\n",
            "encoder.layer.8.output.LayerNorm.weight False\n",
            "encoder.layer.8.output.LayerNorm.bias False\n",
            "encoder.layer.9.attention.self.query.weight False\n",
            "encoder.layer.9.attention.self.query.bias False\n",
            "encoder.layer.9.attention.self.key.weight False\n",
            "encoder.layer.9.attention.self.key.bias False\n",
            "encoder.layer.9.attention.self.value.weight False\n",
            "encoder.layer.9.attention.self.value.bias False\n",
            "encoder.layer.9.attention.output.dense.weight False\n",
            "encoder.layer.9.attention.output.dense.bias False\n",
            "encoder.layer.9.attention.output.LayerNorm.weight False\n",
            "encoder.layer.9.attention.output.LayerNorm.bias False\n",
            "encoder.layer.9.intermediate.dense.weight False\n",
            "encoder.layer.9.intermediate.dense.bias False\n",
            "encoder.layer.9.output.dense.weight False\n",
            "encoder.layer.9.output.dense.bias False\n",
            "encoder.layer.9.output.LayerNorm.weight False\n",
            "encoder.layer.9.output.LayerNorm.bias False\n",
            "encoder.layer.10.attention.self.query.weight True\n",
            "encoder.layer.10.attention.self.query.bias True\n",
            "encoder.layer.10.attention.self.key.weight True\n",
            "encoder.layer.10.attention.self.key.bias True\n",
            "encoder.layer.10.attention.self.value.weight True\n",
            "encoder.layer.10.attention.self.value.bias True\n",
            "encoder.layer.10.attention.output.dense.weight True\n",
            "encoder.layer.10.attention.output.dense.bias True\n",
            "encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "encoder.layer.10.intermediate.dense.weight True\n",
            "encoder.layer.10.intermediate.dense.bias True\n",
            "encoder.layer.10.output.dense.weight True\n",
            "encoder.layer.10.output.dense.bias True\n",
            "encoder.layer.10.output.LayerNorm.weight True\n",
            "encoder.layer.10.output.LayerNorm.bias True\n",
            "encoder.layer.11.attention.self.query.weight True\n",
            "encoder.layer.11.attention.self.query.bias True\n",
            "encoder.layer.11.attention.self.key.weight True\n",
            "encoder.layer.11.attention.self.key.bias True\n",
            "encoder.layer.11.attention.self.value.weight True\n",
            "encoder.layer.11.attention.self.value.bias True\n",
            "encoder.layer.11.attention.output.dense.weight True\n",
            "encoder.layer.11.attention.output.dense.bias True\n",
            "encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "encoder.layer.11.intermediate.dense.weight True\n",
            "encoder.layer.11.intermediate.dense.bias True\n",
            "encoder.layer.11.output.dense.weight True\n",
            "encoder.layer.11.output.dense.bias True\n",
            "encoder.layer.11.output.LayerNorm.weight True\n",
            "encoder.layer.11.output.LayerNorm.bias True\n",
            "pooler.dense.weight True\n",
            "pooler.dense.bias True\n"
          ]
        }
      ],
      "source": [
        "for name, param in xlmt_model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "    if \"encoder.layer.10\" in name or \"encoder.layer.11\" in name or name == 'pooler.dense.weight' or name == 'pooler.dense.bias':\n",
        "        param.requires_grad = True\n",
        "    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUuLjyiGw0GO"
      },
      "outputs": [],
      "source": [
        "class XLMTRegressor(nn.Module):\n",
        "    def __init__(self, model, hidden_count = 20, dropout = 0.2):\n",
        "        super(XLMTRegressor, self).__init__()\n",
        "\n",
        "        self.xlmt = model\n",
        "        self.linear = nn.Linear(768, hidden_count)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.regression = nn.Linear(hidden_count, 1)\n",
        "\n",
        "    def forward(self, input_ids = None, attention_mask = None, labels = None, loss_fn_type = 'pearson'):\n",
        "        encoding_output = self.xlmt(input_ids = input_ids, attention_mask = attention_mask)\n",
        "        # https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPooling\n",
        "        linear_output = self.linear(encoding_output[1])\n",
        "        relu_output = self.relu(linear_output)\n",
        "        dropout_output = self.dropout(relu_output)\n",
        "        final_output = self.regression(dropout_output)\n",
        "        \n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if loss_fn_type == 'mse':\n",
        "                loss_fn = nn.MSELoss()\n",
        "                loss = loss_fn(final_output, labels)\n",
        "            elif loss_fn_type == 'pearson':\n",
        "                pearson = PearsonCorrCoef(num_outputs = 1)\n",
        "                loss = -pearson(torch.squeeze(final_output, 1).to('cpu'), torch.squeeze(labels, 1).to('cpu'))\n",
        "            elif loss_fn_type == 'spearman':\n",
        "                spearman = SpearmanCorrCoef(num_outputs = 1)\n",
        "                loss = -spearman(torch.squeeze(final_output, 1).to('cpu'), torch.squeeze(labels, 1).to('cpu'))\n",
        "            elif loss_fn_type == 'mse+pearson':\n",
        "                mse = nn.MSELoss()\n",
        "                pearson = PearsonCorrCoef(num_outputs = 1)\n",
        "                loss = mse(final_output, labels) - pearson(torch.squeeze(final_output, 1).to('cpu'), torch.squeeze(labels, 1).to('cpu'))\n",
        "\n",
        "        \n",
        "        return SequenceClassifierOutput(loss = loss, logits = final_output, hidden_states = encoding_output.hidden_states, attentions = encoding_output.attentions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh2aua1N1xT9"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39H3sDG-6ZKD",
        "outputId": "208aa05e-7d94-4239-cd85-3734afe13e50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "100%|██████████| 668/668 [15:43<00:00,  1.41s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 49.94240228753341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:53<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 41.402366286829896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:54<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 39.845386003193106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:53<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 39.78378315975792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:55<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 37.39133458388479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:55<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 39.354781552364955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:54<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 35.09466244045057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:54<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 35.13221469678377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:51<00:00,  1.42s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 40.21811470232512\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 668/668 [15:54<00:00,  1.43s/it]\n",
            "100%|██████████| 38/38 [00:36<00:00,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 39.55422441582931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = RegressionIntimacyDataset(train_data, xlmt_tokenizer), RegressionIntimacyDataset(val_data, xlmt_tokenizer)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size = BATCH_SIZE, shuffle = True)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr = learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        model.train()\n",
        "        # train the model on train data\n",
        "        for train_batch in tqdm(train_dataloader):\n",
        "            train_label = train_batch['labels'].to(device)\n",
        "            mask = train_batch['attention_mask'].to(device)\n",
        "            input_id = train_batch['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            outputs = model(input_id, mask, train_label, loss_fn_type = 'pearson')\n",
        "\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        torch.save(model.state_dict(), f'{PATH_TO_SAVE}_{epoch_num}')\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        # evaluate the model on validation data\n",
        "        eval_losses = []\n",
        "        for val_batch in tqdm(val_dataloader):\n",
        "            val_label = val_batch['labels'].to(device)\n",
        "            mask = val_batch['attention_mask'].to(device)\n",
        "            input_id = val_batch['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_id, mask, val_label, loss_fn_type = 'pearson')\n",
        "            \n",
        "            model_pred = outputs.logits\n",
        "            eval_losses.append(outputs.loss.item())\n",
        "\n",
        "        print(f'loss = {mean(eval_losses)}')\n",
        "\n",
        "\n",
        "              \n",
        "model = XLMTRegressor(xlmt_model)\n",
        "df_train, df_val, df_test = train_val_test_split(df)\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87n_a9buJo6g"
      },
      "source": [
        "## evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ5UPsBP6b8h",
        "outputId": "8e256789-5380-4c1c-c959-3bdedcfccbfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 594/594 [00:37<00:00, 15.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss = 38.54456173581689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "    test = RegressionIntimacyDataset(test_data, xlmt_tokenizer)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    model.eval()\n",
        "    # evaluate the model on test data\n",
        "    with torch.no_grad():\n",
        "        test_losses = []\n",
        "        for test_batch in tqdm(test_dataloader):\n",
        "            test_label = test_batch['labels'].to(device)\n",
        "            mask = test_batch['attention_mask'].to(device)\n",
        "            input_id = test_batch['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            outputs = model(input_id, mask, test_label, loss_fn_type = 'pearson')\n",
        "\n",
        "            model_pred = outputs.logits\n",
        "            test_losses.append(outputs.loss.item())\n",
        "    \n",
        "    print(f'loss = {mean(test_losses)}')\n",
        "    \n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_UBPU0ww_00"
      },
      "source": [
        "## evaluation on test data codalab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE7FojiKwMkc"
      },
      "outputs": [],
      "source": [
        "def read_test_data(file_path = \"semeval_test.csv\"):\n",
        "  df = pd.read_csv(file_path)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbp-HN7kzjFh"
      },
      "outputs": [],
      "source": [
        "class TestRegressionIntimacyDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.all_data = df\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        # tokenized texts of our dataset\n",
        "        self.encodings = {}\n",
        "        self.encodings['input_ids'] = np.array([np.array(self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")['input_ids'])\n",
        "                                for text in self.all_data['text']])\n",
        "        \n",
        "        self.encodings['attention_mask'] = np.array([np.array(self.tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")['attention_mask'])\n",
        "                                for text in self.all_data['text']])\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.all_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfNwBfBr1C7M"
      },
      "outputs": [],
      "source": [
        "MODEL = \"cardiffnlp/twitter-xlm-roberta-base\"\n",
        "xlmt_tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1WZHcNkotRI",
        "outputId": "2749797f-f99a-494b-b67d-ae27883aa569"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "xlmt_model = AutoModel.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YllGTwGoGk_",
        "outputId": "7cb9aa6c-34b6-4eca-90c9-82ed5252e0ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = XLMTRegressor(xlmt_model)\n",
        "model.load_state_dict(torch.load(f'{PATH_FOR_READ}_{EPOCHS-1}'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi-AqF3-w_JQ"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_data):\n",
        "    # generating output of the mode for test dataset\n",
        "    test = TestRegressionIntimacyDataset(test_data, xlmt_tokenizer)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=32)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    model_predictions = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_batch in tqdm(test_dataloader):\n",
        "            mask = test_batch['attention_mask'].to(device)\n",
        "            input_id = test_batch['input_ids'].squeeze(1).to(device)\n",
        "            outputs = model(input_id, mask, loss_fn_type = 'pearson')\n",
        "            model_pred = outputs.logits\n",
        "            model_predictions.append(model_pred)\n",
        "    return model_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjVWchwPxZ8t",
        "outputId": "993c46ea-fa90-4421-97a2-260a739ddc23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [06:43<00:00,  1.06it/s]\n"
          ]
        }
      ],
      "source": [
        "# df_coda = read_test_data(\"train.csv\")\n",
        "df_coda = read_test_data(\"semeval_test.csv\")    \n",
        "outputs = predict(model, df_coda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKe1ZveT3UeK"
      },
      "outputs": [],
      "source": [
        "flat_predictions = [item.cpu().numpy()[0] for sublist in outputs for item in sublist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbRgo-xr765B"
      },
      "outputs": [],
      "source": [
        "min_flat = min(flat_predictions)\n",
        "max_flat = max(flat_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2T39ho43mZZ",
        "outputId": "9246b84e-0107-4cc7-a22b-c7261b31c80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13697\n"
          ]
        }
      ],
      "source": [
        "print(len(flat_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGfd-NmS3ukC"
      },
      "outputs": [],
      "source": [
        "df_coda['predictions'] = flat_predictions\n",
        "# df_coda['predictions'] = df_coda['predictions'].apply(lambda x: (x - min_flat) * 4 / (max_flat - min_flat) + 1)\n",
        "# df_coda['predictions'] = df_coda['predictions'].apply(lambda x: x/10)\n",
        "df_coda['predictions'] = df_coda['predictions'].apply(lambda x: 1 if x < 1 else x)\n",
        "df_coda['predictions'] = df_coda['predictions'].apply(lambda x: 5 if x > 5 else x)\n",
        "df_coda.to_csv('results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuajDvIG5Poy",
        "outputId": "1b6151fa-3120-4da0-d4b4-c1f903aa340e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3039"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_coda['predictions'].argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz_QeArc6bwA",
        "outputId": "9047d90f-01b8-4b18-a19d-186cf9cafdce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_coda['predictions'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWcaH2bM6AC5",
        "outputId": "4639f954-38dd-4f38-8ec7-4ee86e1d62d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n",
            "#1Ene 1942 se firma la declaración de la Naciones Unidas. #60AñosDeRevoluciónCubana #Feliz2019 http\n",
            "Spanish\n"
          ]
        }
      ],
      "source": [
        "print(df_coda['predictions'].argmin())\n",
        "print(df_coda['text'][14])\n",
        "print(df_coda['language'][14])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG07xQ-a5oM7",
        "outputId": "30bd48c0-a871-45ad-a400-4192b76bcc6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@user ily bestie💞\n",
            "Dutch\n"
          ]
        }
      ],
      "source": [
        "print(df_coda['text'][12021])\n",
        "print(df_coda['language'][12021])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "ReGeJhEu5qRh",
        "outputId": "4084d09b-a889-4b15-8f63-bc8ce0ccf429"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-2d8c8fc3d55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# find subtraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_coda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf_coda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ],
      "source": [
        "# find subtraction\n",
        "sub = df_coda['predictions'] - df_coda['label']\n",
        "print(abs(sub).argmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSY38G5A6g6D"
      },
      "outputs": [],
      "source": [
        "print(df_coda['text'][2439])\n",
        "print(df_coda['language'][2439])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "bc557b74f5c7d96f3a4fff2167a95a4252e316909755ef10c67da981ac2e9136"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "051da38cb7814368bf653f970a5767ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5deefc48e0b645c6ad3a9fd108317bf2",
            "placeholder": "​",
            "style": "IPY_MODEL_8f0a52f15d944f59bd5e27576cf9c711",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "0c705f2e20b54fcd857fefcb32652c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db57a43ada346d2a99fd08b873a8496": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11b367b6a93f471f97f2b5957a5c2aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "157f0cd2c7c44ccbb3c0d4d608d70a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52c41d3b2a734c26a89f6a5176635ff0",
              "IPY_MODEL_abbeec30301c4df8a12f41e8369515b0",
              "IPY_MODEL_58bc82e67c064ee19bd7e784628a281c"
            ],
            "layout": "IPY_MODEL_ef68bdc26ae84cfc986bf68f5d20525e"
          }
        },
        "17b69830c2d741f0b1692dbf7efefbad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18eece111e804e3a8b7c1dafadf6ae9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_051da38cb7814368bf653f970a5767ac",
              "IPY_MODEL_9256856ee0c74f2281792d669096bb14",
              "IPY_MODEL_eb21d8c4ebd3409c9d560799fb7b2b88"
            ],
            "layout": "IPY_MODEL_760c65aeec4543848d01799e1c01578d"
          }
        },
        "1bbdb34647bd4d32a1735e8cef3fb098": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29165982dd714021b4410a1a61de3498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292ea552cfe7454aaeaebb5864140231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c2a2742c5f94b75b8a77d1fbdca6dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9702942a30f34ac694d481c3eced7eac",
              "IPY_MODEL_f32e18b6e30f4a728b07f8c68e463cf1",
              "IPY_MODEL_99922cceccef4612bea30bd3d1080ae3"
            ],
            "layout": "IPY_MODEL_f818bf2fc7ac439390684fea3fe1f8bd"
          }
        },
        "4022d31cab9a4586bf4d9e64e298cff7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab3a8192a4f4eae87cc5360263bfa98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d90a60a0b474194817babc5ba8c1e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52c41d3b2a734c26a89f6a5176635ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1db388afcf4501ae85699ff8ce45b1",
            "placeholder": "​",
            "style": "IPY_MODEL_a7834e3f18f145d5a2e9d1f99b9e7657",
            "value": "Downloading (…)ncepiece.bpe.model&quot;;: 100%"
          }
        },
        "564502658a134864a7c47e2cc168f24a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bc82e67c064ee19bd7e784628a281c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db57a43ada346d2a99fd08b873a8496",
            "placeholder": "​",
            "style": "IPY_MODEL_4ab3a8192a4f4eae87cc5360263bfa98",
            "value": " 5.07M/5.07M [00:00&lt;00:00, 93.4MB/s]"
          }
        },
        "5deefc48e0b645c6ad3a9fd108317bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f03d9ef06d4f1e952241bade0bb6e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63959ef9d01d49869b61cc6ef247634a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1514a8f5b4a48bfac81aedfdbf7d4f4",
            "max": 9096718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6966da6ad71e434697cdea564d84e13d",
            "value": 9096718
          }
        },
        "6966da6ad71e434697cdea564d84e13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "760c65aeec4543848d01799e1c01578d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b1db388afcf4501ae85699ff8ce45b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81251e1aaded4a2eb7b2caa6a55a376e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f0a52f15d944f59bd5e27576cf9c711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9256856ee0c74f2281792d669096bb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed66ba067e9493ead2943783c39c2b4",
            "max": 1113236958,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1e1391b523f42d9b71103cee6cacc25",
            "value": 1113236958
          }
        },
        "9702942a30f34ac694d481c3eced7eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4022d31cab9a4586bf4d9e64e298cff7",
            "placeholder": "​",
            "style": "IPY_MODEL_81251e1aaded4a2eb7b2caa6a55a376e",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "99922cceccef4612bea30bd3d1080ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564502658a134864a7c47e2cc168f24a",
            "placeholder": "​",
            "style": "IPY_MODEL_292ea552cfe7454aaeaebb5864140231",
            "value": " 652/652 [00:00&lt;00:00, 20.5kB/s]"
          }
        },
        "9c1e166e0c7340ffbef941155756c634": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7834e3f18f145d5a2e9d1f99b9e7657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abbeec30301c4df8a12f41e8369515b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17b69830c2d741f0b1692dbf7efefbad",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbdb34647bd4d32a1735e8cef3fb098",
            "value": 5069051
          }
        },
        "b1e1391b523f42d9b71103cee6cacc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b46e3dc2798040b98e22d4ea8b109ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43f625ab61f4545ab7d4aa1a811f9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c1e166e0c7340ffbef941155756c634",
            "placeholder": "​",
            "style": "IPY_MODEL_29165982dd714021b4410a1a61de3498",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "c6580453586842b6875fd83a52b64abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b46e3dc2798040b98e22d4ea8b109ab2",
            "placeholder": "​",
            "style": "IPY_MODEL_eb7fc6cb679041539e24fa918dd7a2ab",
            "value": " 9.10M/9.10M [00:02&lt;00:00, 4.56MB/s]"
          }
        },
        "c6ad614603ed4d87b6953b9fb65071c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e630bda7e0194373af5241d6b142df12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43f625ab61f4545ab7d4aa1a811f9a5",
              "IPY_MODEL_63959ef9d01d49869b61cc6ef247634a",
              "IPY_MODEL_c6580453586842b6875fd83a52b64abd"
            ],
            "layout": "IPY_MODEL_0c705f2e20b54fcd857fefcb32652c8d"
          }
        },
        "eb21d8c4ebd3409c9d560799fb7b2b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f03d9ef06d4f1e952241bade0bb6e2",
            "placeholder": "​",
            "style": "IPY_MODEL_4d90a60a0b474194817babc5ba8c1e60",
            "value": " 1.11G/1.11G [00:04&lt;00:00, 190MB/s]"
          }
        },
        "eb7fc6cb679041539e24fa918dd7a2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef68bdc26ae84cfc986bf68f5d20525e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1514a8f5b4a48bfac81aedfdbf7d4f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32e18b6e30f4a728b07f8c68e463cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ad614603ed4d87b6953b9fb65071c5",
            "max": 652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11b367b6a93f471f97f2b5957a5c2aed",
            "value": 652
          }
        },
        "f818bf2fc7ac439390684fea3fe1f8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed66ba067e9493ead2943783c39c2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
